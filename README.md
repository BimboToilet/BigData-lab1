# Запуск многоконтейнерного приложения
`docker compose up --build -d`  
  
Для доступа к `dashboard` нужно в браузере открыть `localhost:8501`, либо `0.0.0.0:8501`.  
  
## Остановка приложения
`docker compose down -v`  
  
# Влияние разных `replication.factor` и `min.insync.replicas` в конфигурации топиков
Кластер состоит из трёх брокеров.  
  
В файле `docker-compose.yml` для используемых топиков `replication.factor = 3`, `min.insync.replicas = 2`. Для каждого топика отведено `3` партиции. Таким образом, для каждой из `3` партиций существует ещё `2` копии, распределенные по брокерам в кластере, что обеспечивает отказоустойчивость.  
  
Согласно значению `min.insync.replicas`, для подтверждения успешной записи `2` из `3` партиций (копии + лидер) должны подтвердить запись. В коде для всех `Producer` жёстко зафиксировано `acks = all`.  
  
Далее поведение системы будет рассмотрено на примере логов `Consumer`, отображающего информацию в `dashboard`.  
  
## `replication.factor = 3`, `min.insync.replicas = 2`
Такая конфигурация обеспечивает высокую надежность при сохранении доступности на запись.  
  
В этом случае, при отключении одного из трёх имеющихся брокеров, система продолжает работать в штатном режиме, так как минимальное количество необходимых реплик равно `2` - столько у нас остается и брокеров:  
  
<img width="984" height="373" alt="Интенсивность сообщений после отключения первого брокера" src="https://github.com/user-attachments/assets/edf8f9d3-5ee4-4543-b070-6559824503e5" />  
  
Отключение первого брокера отражено на картинке на пятом баре. Интенсивность сообщений уменьшилась из-за необходимости переподключений.  
  
<img width="1405" height="270" alt="Логи контейнера с dashboard в момент отключения первого брокера" src="https://github.com/user-attachments/assets/e61d173b-c667-449d-a945-e113dfe64c09" />  
  
На картинке представлены логи момента отключения первого брокера. Видно, что появились ошибки подключения, однако получение сообщений продолжилось.  
  
После отключения второго брокера обновление `dashboard` прекратилось, так как перестали приходить новые сообщения:  
  
<img width="958" height="377" alt="Интенсивность сообщений после отключения второго брокера" src="https://github.com/user-attachments/assets/6ac56a4d-dfc6-410f-ab96-e3ee02858e3b" />  
  
На картинке отключение второго брокера отражено на самом последнем баре - `Consumer` прочитал небольшую долю сообщений перед остановкой потока сообщений.  
  
<img width="1401" height="168" alt="Логи контейнера с dashboard в момент отключения второго брокера" src="https://github.com/user-attachments/assets/28d60a7f-24e2-490c-aa38-f3444c532d54" />  
  
Как и ожидалось, после отключения второго брокера все отправляемые от `Producer` сообщения перестали получать необходимое количество подтверждений, из-за чего новые сообщения перестали фиксироваться в партициях и весь пайплайн "замер".  
  
## `replication.factor = 1`, `min.insync.replicas = 2`
В этом случае предполагалось, что ни одно сообщение не будет передано к брокерам, так как мы требуем, чтобы как минимум две партиции подтвердили запись, при том что у нас всего одна копия для каждой партиции.  
  
Однако Kafka автоматически изменило значение `min.insync.replicas = 1`, поэтому сообщения передавались по пайплайну, как в прошлом случае, до тех пор, пока не были отключены все три брокера в кластере.  
  
Далее представлены логи отключения двух брокеров, после которых получение сообщений не прекратилось:  
  
<img width="1403" height="303" alt="Отключение первого брокера" src="https://github.com/user-attachments/assets/f0d762db-62c8-4c4d-b53f-8988dbb828b4" />  
  
<img width="1405" height="358" alt="Отключение второго брокера" src="https://github.com/user-attachments/assets/01c079a4-c7bb-4ce2-b093-ea7a88b3ab57" />  
  
В данном случае при отключении любого брокера происходит безвозвратная потеря информации, так как у нас для каждой партиции лишь одна копия (оригинал).  
  
## `replication.factor = 3`, `min.insync.replicas = 3`
Такая конфигурация характеризуется экстремальными требованиями к сохранности данных, где целостность важнее доступности.  
  
Здесь получение сообщений прекратится после отключения первого же брокера.  
  
## `replication.factor = 3`, `min.insync.replicas = 1`
При такой конфигурации мы имеем максимальную отказоустойчивость на запись, так как сообщений будут идти до тех пор, пока жив хотя бы один брокер.  
  
Однако здесь высоки риски потери данных. Одна единственная партиция может подтвердить запись, при том что в реальности данные записались только на неё, так что в случае отказа работы брокера, на котором хранится данная партиция, мы можем потерять данные.  

